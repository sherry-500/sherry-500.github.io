<!DOCTYPE html>
<html lang=zh>
<head>
    <!-- so meta -->
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="HandheldFriendly" content="True">
    <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=5" />
    <meta name="description" content="之前参加otto多目标推荐系统比赛的时候，尝试过训练mmoe模型，发现了一个奇怪的现象：模型会在第一个epoch后，在训练集上的损失趋于不变，下降幅度明显变缓，而在测试集上的损失会略有增加。最初，我怀疑可能是出现了梯度消失，但是因为mmoe是业界已经成功应用的模型，模型结构以及损失函数的选择应该是不会有问题的，并且我也对特征进行了标准化处理。随后我对梯度进行了可视化，结果表明并没有出现梯度消失。因">
<meta property="og:type" content="article">
<meta property="og:title" content="one-epoch phenomena in Deep Learning Recommendation Models">
<meta property="og:url" content="https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/index.html">
<meta property="og:site_name" content="sherry-500">
<meta property="og:description" content="之前参加otto多目标推荐系统比赛的时候，尝试过训练mmoe模型，发现了一个奇怪的现象：模型会在第一个epoch后，在训练集上的损失趋于不变，下降幅度明显变缓，而在测试集上的损失会略有增加。最初，我怀疑可能是出现了梯度消失，但是因为mmoe是业界已经成功应用的模型，模型结构以及损失函数的选择应该是不会有问题的，并且我也对特征进行了标准化处理。随后我对梯度进行了可视化，结果表明并没有出现梯度消失。因">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://sherry-500.github.io/images/one-epoch_1.png">
<meta property="og:image" content="https://sherry-500.github.io/images/one-epoch_2.png">
<meta property="og:image" content="https://sherry-500.github.io/images/one-epoch_3.png">
<meta property="og:image" content="https://sherry-500.github.io/images/one-epoch_4.png">
<meta property="article:published_time" content="2025-08-04T02:03:45.000Z">
<meta property="article:modified_time" content="2025-08-04T11:54:17.225Z">
<meta property="article:author" content="sherry-500">
<meta property="article:tag" content="Deep Learning">
<meta property="article:tag" content="Recommendation System">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="https://sherry-500.github.io/images/one-epoch_1.png">
    
    
      
        
          <link rel="shortcut icon" href="/images/favicon.ico">
        
      
      
        
          <link rel="icon" type="image/png" href="/images/favicon-192x192.png" sizes="192x192">
        
      
      
        
          <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon.png">
        
      
    
    <!-- title -->
    <title>one-epoch phenomena in Deep Learning Recommendation Models</title>
    <!-- async scripts -->
    <!-- Google Analytics -->


    <!-- Umami Analytics -->


    <!-- styles -->
    
<link rel="stylesheet" href="/css/style.css">

    <!-- persian styles -->
    
    <!-- rss -->
    
    
	<!-- mathjax -->
	
		<script type="text/x-mathjax-config">
		  MathJax.Hub.Config({
			tex2jax: {
			  skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
			  inlineMath: [['$','$']]
			}
		  });
		</script>
		<script src='https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-MML-AM_CHTML' async></script>
	
<meta name="generator" content="Hexo 7.3.0"><style>mjx-container[jax="SVG"] {
  direction: ltr;
}

mjx-container[jax="SVG"] > svg {
  overflow: visible;
}

mjx-container[jax="SVG"][display="true"] {
  display: block;
  text-align: center;
  margin: 1em 0;
}

mjx-container[jax="SVG"][justify="left"] {
  text-align: left;
}

mjx-container[jax="SVG"][justify="right"] {
  text-align: right;
}

g[data-mml-node="merror"] > g {
  fill: red;
  stroke: red;
}

g[data-mml-node="merror"] > rect[data-background] {
  fill: yellow;
  stroke: none;
}

g[data-mml-node="mtable"] > line[data-line] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > rect[data-frame] {
  stroke-width: 70px;
  fill: none;
}

g[data-mml-node="mtable"] > .mjx-dashed {
  stroke-dasharray: 140;
}

g[data-mml-node="mtable"] > .mjx-dotted {
  stroke-linecap: round;
  stroke-dasharray: 0,140;
}

g[data-mml-node="mtable"] > svg {
  overflow: visible;
}

[jax="SVG"] mjx-tool {
  display: inline-block;
  position: relative;
  width: 0;
  height: 0;
}

[jax="SVG"] mjx-tool > mjx-tip {
  position: absolute;
  top: 0;
  left: 0;
}

mjx-tool > mjx-tip {
  display: inline-block;
  padding: .2em;
  border: 1px solid #888;
  font-size: 70%;
  background-color: #F8F8F8;
  color: black;
  box-shadow: 2px 2px 5px #AAAAAA;
}

g[data-mml-node="maction"][data-toggle] {
  cursor: pointer;
}

mjx-status {
  display: block;
  position: fixed;
  left: 1em;
  bottom: 1em;
  min-width: 25%;
  padding: .2em .4em;
  border: 1px solid #888;
  font-size: 90%;
  background-color: #F8F8F8;
  color: black;
}

foreignObject[data-mjx-xml] {
  font-family: initial;
  line-height: normal;
  overflow: visible;
}

.MathJax path {
  stroke-width: 3;
}

mjx-container[display="true"] {
  overflow: auto hidden;
}

mjx-container[display="true"] + br {
  display: none;
}
</style></head>

<body class="max-width mx-auto px3 ltr">    
      <div id="header-post">
  <a id="menu-icon" href="#" aria-label="目录"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="menu-icon-tablet" href="#" aria-label="目录"><i class="fa-solid fa-bars fa-lg"></i></a>
  <a id="top-icon-tablet" href="#" aria-label="顶部" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');" style="display:none;"><i class="fa-solid fa-chevron-up fa-lg"></i></a>
  <span id="menu">
    <span id="nav">
      <ul>
        <!--
       --><li><a href="/">首页</a></li><!--
     --><!--
       --><li><a href="/about/">关于</a></li><!--
     --><!--
       --><li><a href="/archives/">归档</a></li><!--
     --><!--
       --><li><a href="/tags/">标签</a></li><!--
     --><!--
       --><li><a href="/categories/">分类</a></li><!--
     --><!--
       --><li><a href="/search/">搜索</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/probberechts">项目</a></li><!--
     -->
      </ul>
    </span>
    <br/>
    <span id="actions">
      <ul>
        
        
        <li><a class="icon" aria-label="下一篇" href="/2025/08/02/Tutorial-for-common-optimizers/"><i class="fa-solid fa-chevron-right" aria-hidden="true" onmouseover="$('#i-next').toggle();" onmouseout="$('#i-next').toggle();"></i></a></li>
        
        <li><a class="icon" aria-label="返回顶部" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up" aria-hidden="true" onmouseover="$('#i-top').toggle();" onmouseout="$('#i-top').toggle();"></i></a></li>
        <li><a class="icon" aria-label="分享文章" href="#"><i class="fa-solid fa-share-alt" aria-hidden="true" onmouseover="$('#i-share').toggle();" onmouseout="$('#i-share').toggle();" onclick="$('#share').toggle();return false;"></i></a></li>
      </ul>
      <span id="i-prev" class="info" style="display:none;">上一篇</span>
      <span id="i-next" class="info" style="display:none;">下一篇</span>
      <span id="i-top" class="info" style="display:none;">返回顶部</span>
      <span id="i-share" class="info" style="display:none;">分享文章</span>
    </span>
    <br/>
    <div id="share" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/"><i class="fab fa-facebook " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&text=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-twitter " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-linkedin " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&is_video=false&description=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-pinterest " aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=one-epoch phenomena in Deep Learning Recommendation Models&body=Check out this article: https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/"><i class="fa-solid fa-envelope " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-get-pocket " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-reddit " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-stumbleupon " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-digg " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&name=one-epoch phenomena in Deep Learning Recommendation Models&description="><i class="fab fa-tumblr " aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&t=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-hacker-news " aria-hidden="true"></i></a></li>
</ul>

    </div>
    
    
      <div id="toc">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#model-related-factors"><span class="toc-number">1.</span> <span class="toc-text">Model-Related Factors</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">模型结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E9%87%8F"><span class="toc-number">1.2.</span> <span class="toc-text">模型的参数量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">1.3.</span> <span class="toc-text">激活函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#batch-size"><span class="toc-number">1.4.</span> <span class="toc-text">Batch size</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#optimization-algorithm"><span class="toc-number">1.5.</span> <span class="toc-text">Optimization Algorithm</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#weight-decay-and-dropout"><span class="toc-number">1.6.</span> <span class="toc-text">weight decay and dropout</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#feature-related-factors"><span class="toc-number">2.</span> <span class="toc-text">Feature-Related Factors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E5%88%86%E5%B8%83%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="toc-number">4.</span> <span class="toc-text">联合分布的差异</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%BF%AB%E9%80%9F%E9%80%82%E5%BA%94"><span class="toc-number">5.</span> <span class="toc-text">对训练样本的快速适应</span></a></li></ol>
      </div>
    
  </span>
</div>

    
    <div class="content index py4 ">
        
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">
  <header>
    
    <h1 class="posttitle p-name" itemprop="name headline">
        one-epoch phenomena in Deep Learning Recommendation Models
    </h1>



    <div class="meta">
      <span class="author p-author h-card" itemprop="author" itemscope itemtype="http://schema.org/Person">
        <span class="p-name" itemprop="name">sherry-500</span>
      </span>
      
    <div class="postdate">
      
        <time datetime="2025-08-04T02:03:45.000Z" class="dt-published" itemprop="datePublished">2025-08-04</time>
        
      
    </div>


      
    <div class="article-category">
        <i class="fa-solid fa-archive"></i>
        <a class="category-link" href="/categories/Deep-Learning/">Deep Learning</a>
    </div>


      
    <div class="article-tag">
        <i class="fa-solid fa-tag"></i>
        <a class="p-category" href="/tags/Deep-Learning/" rel="tag">Deep Learning</a>, <a class="p-category" href="/tags/Recommendation-System/" rel="tag">Recommendation System</a>
    </div>


    </div>
  </header>
  

  <div class="content e-content" itemprop="articleBody">
    <p>之前参加otto多目标推荐系统比赛的时候，尝试过训练mmoe模型，发现了一个奇怪的现象：模型会在第一个epoch后，在训练集上的损失趋于不变，下降幅度明显变缓，而在测试集上的损失会略有增加。最初，我怀疑可能是出现了梯度消失，但是因为mmoe是业界已经成功应用的模型，模型结构以及损失函数的选择应该是不会有问题的，并且我也对特征进行了标准化处理。随后我对梯度进行了可视化，结果表明并没有出现梯度消失。因为训练集的规模比较大，并且在我尝试了增加训练数据，调节隐层单元数目，embedding维度，MLP层数的情况下，上述现象依然存在，所以我产生了疑问：真的发生过拟合了吗？，如果发生了，为什么会在第一个epoch后就会发生（毕竟已经打乱了数据集）？这与我在其他领域的实践经验是非常不同的，在这之前，我从来没有遇到过只训练了一个epoch就过拟合的情况。</p>
<p>机缘巧合的是，在看一些关于生成式推荐的论文
时，我恰好看到有篇论文中提到了one-epoch现象，并引用了<a target="_blank" rel="noopener" href="https://arxiv.org/pdf/2209.06053">这篇论文</a>，果然可以解答我的疑惑。</p>
<p>首先是对one-epoch现象的总结，one-epoch现象是指模型的表现会在第二个epoch开始时出现显著的退化。在CTR模型的实际应用中，这种现象被广泛地发现，因此，模型的最佳性能通常在只训练了一个epoch时达到。这篇论文中总结了one-epoch现象产生的三种原因：</p>
<ul>
<li>模型结构</li>
<li>使用了有快速的收敛速度的优化算法</li>
<li>特征的稀疏性</li>
</ul>
<p>论文的作者首先在生产数据集和两个公开数据集上进行试验，证明了one-epoch现象在基于深度学习的CTR预测模型中是广泛存在，</p>
<p>为了研究one-epoch现象产生的原因，作者从两个方面开展试验：模型相关的因素和特征相关的因素</p>
<h3 id="model-related-factors">Model-Related Factors</h3>
<p>在这一部分，作者研究了模型相关因素的影响，包括模型结构，模型的参数量，batch
size，激活函数，优化器和学习率的选择以及一些被用于缓解过拟合的技术，如权重衰减和dropout。</p>
<h4 id="模型结构">模型结构</h4>
<p>考虑到推荐系统的数据的高维稀疏性，DLRMs通常包含embedding层和MLP结构。原始的输入，通常包括稀疏的类别型特征，先使用embedding层映射到低维向量，再使用池化层将多个特征域（如历史点击物品的id）转换成固定长度的向量，最后拼接在一起作为MLP的输入。</p>
<p><img src="/images/one-epoch_1.png"></p>
<p>作者将DNN与LR模型做了对比，发现LR模型虽然出现了缓慢的过拟合，但是并没有发生one-epoch现象。基于DNN的模型都出现了明显的one-epoch过拟合，这说明了one-epoch现象与整合了embedding特征和MLP结构的模型结构是紧密相关的。</p>
<h4 id="模型的参数量">模型的参数量</h4>
<p>作者调整了embedding维度和MLP的隐藏单元数目和层数，证明模型参数的不同设置不能缓解one-epoch现象。</p>
<h4 id="激活函数">激活函数</h4>
<p>作者发现激活函数几乎不会对one-epoch现象产生影响</p>
<h4 id="batch-size">Batch size</h4>
<p>作者分析了不同batch size的影响，发现改变batch
size不能缓解one-epoch</p>
<h4 id="optimization-algorithm">Optimization Algorithm</h4>
<p>作者在这一部分研究了优化器和学习率的影响。除了Adam优化器，作者还使用了RMSprop和SGD。相比于SGD，Adam和RMSprop具有更快的收敛速度，但它们有更明显的one-epoch现象。</p>
<p>学习率和one-epoch现象也是相关的。一个极端小的学习率下，one-epoch现象不太明显，但这是以模型的表现为代价的。总体来说，可以加快模型收敛的优化算法更有可能出现one-epoch现象。</p>
<h4 id="weight-decay-and-dropout">weight decay and dropout</h4>
<p>试验发现，weight
decay不能提升模型的性能或是缓解one-epoch问题。dropout也不能解决one-epoch问题。</p>
<h3 id="feature-related-factors">Feature-Related Factors</h3>
<p>工业界的CTR预测模型使用的特征可以大致分为四种：用户侧特征，用户行为序列，候选物品侧特征，上下文特征。在工业场景的实践中，所有的特征都被预处理成离散型特征（连续型特征经过分桶），每一种特征取值用一个id表示。</p>
<p>生产环境的数据集的特征具有稀疏性，即特征有大量的不同取值，但是每种取值的平均出现次数很少。并且，id呈现出长尾分布，如果将数据集按照id的出现频率绘制分布图，可以发现，出现频率最低的50%的id只占据了2.5%的出现次数。</p>
<p><img src="/images/one-epoch_2.png"></p>
<p>为了展示特征稀疏性的影响，走着通过两种技术减少特征稀疏性：filter，hash。filter方法只保留出现频率最高的<span class="math inline"><em>m</em></span>比例的id，将其他的id替换为一个默认id。hash方法将每个id映射到一个大小为id总数的<span class="math inline"><em>m</em></span>比例的空间。随着<span class="math inline"><em>m</em></span>的减小，特征的稀疏性减小，one-epoch现象也相应地得到缓解。然而，模型表现的退化也不可避免。</p>
<p><img src="/images/one-epoch_3.png"></p>
<p>还有一种直接的减少稀疏性的方法是移除细粒度的特征，作者发现移除生产环境的数据集中的物品id和历史物品id后，不会发生one-epoch现象。</p>
<h3 id="总结">总结</h3>
<p>尽管我们可以通过改变一些因素来缓解one-epoch问题，但都会导致模型表现或多或少的退化。最佳表现通常发生在只训练一个epoch之后。因此，很多工业界的推荐系统对每个样本只训练一次。除此以外，作者还探索了不同的训练范式，希望可以超过只训练一个epoch的模型，比如微调部分参数和学习率衰减，但都没有展现出明显的性能提升。</p>
<hr>
<p>除了上面的实验以外，作者还做出假设以解释one-epoch现象。令<span class="math inline"><em>E</em><em>M</em><em>B</em>(<em>x</em>)</span>表示样本<span class="math inline"><em>x</em></span>经过embedding层后的中间表示，MLP在联合概率分布<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em>), <em>y</em>)</span>上训练。用<span class="math inline"><em>x</em><sub>trained</sub></span>表示训练过的样本，<span class="math inline"><em>x</em><sub>untrained</sub></span>表示没有参与训练的样本，比如，在第一个epoch中的样本是没有训练的，到了第二个epoch都是参与过训练的。作者假设<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em><sub>untrained</sub>), <em>y</em>)</span>与<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em><sub>trained</sub>), <em>y</em>)</span>有很大的差异。在第二个epoch开始的时候，MLP迅速适应经验分布<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em><sub>trained</sub>), <em>y</em>)</span>，导致了过拟合的突然发生，也就是one-epoch现象。</p>
<h3 id="联合分布的差异">联合分布的差异</h3>
<p>直接计算<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em>), <em>y</em>)</span>的变化是很困难的，为了量化这种变化，作者提出利用嵌入向量的可分离特性。在CTR预测任务中，可分离特性描述了分开点击和未点击样本的难度。具体的，使用<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em>), <em>y</em> = 0)</span>和<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em>), <em>y</em> = 1)</span>之间的<span class="math inline">𝒜</span>-distance表示可分离性。为了计算<span class="math inline">𝒜</span>-distance，我们需要训练一个二元分类器<span class="math inline"><em>h</em></span>。令<span class="math inline"><em>e</em><em>r</em><em>r</em>(<em>h</em>)</span>表示分类器的损失，将<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em>), <em>y</em> = 0)</span>和<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em>), <em>y</em> = 1)</span>之间的<span class="math inline">𝒜</span>-distance的标记为<span class="math inline">𝒜(𝒟(+, −))</span>，计算方式如下： <span class="math display"><mjx-container class="MathJax" jax="SVG" display="true"><svg style="vertical-align: -0.566ex;" xmlns="http://www.w3.org/2000/svg" width="28.739ex" height="2.262ex" role="img" focusable="false" viewBox="0 -750 12702.7 1000"><g stroke="currentColor" fill="currentColor" stroke-width="0" transform="scale(1,-1)"><g data-mml-node="math"><g data-mml-node="mtable"><g data-mml-node="mtr"><g data-mml-node="mtd"><g data-mml-node="TeXAtom" data-mjx-texclass="ORD"><g data-mml-node="mi"><path data-c="41" d="M576 668Q576 688 606 708T660 728Q676 728 675 712V571Q675 409 688 252Q696 122 720 57Q722 53 723 50T728 46T732 43T737 41T743 39L754 45Q788 61 803 61Q819 61 819 47Q818 43 814 35Q799 15 755 -7T675 -30Q659 -30 648 -25T630 -8T621 11T614 34Q603 77 599 106T594 146T591 160V163H460L329 164L316 145Q241 35 196 -7T119 -50T59 -24T30 43Q30 75 46 100T74 125Q81 125 83 120T88 104T96 84Q118 57 151 57Q189 57 277 182Q432 400 542 625L559 659H567Q574 659 575 660T576 668ZM584 249Q579 333 577 386T575 473T574 520V581L563 560Q497 426 412 290L372 228L370 224H371L383 228L393 232H586L584 249Z"></path></g></g><g data-mml-node="mo" transform="translate(819,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="TeXAtom" data-mjx-texclass="ORD" transform="translate(1208,0)"><g data-mml-node="mi"><path data-c="44" d="M37 475Q19 475 19 487Q19 536 103 604T327 682H356Q386 683 408 683H419Q475 683 506 681T582 668T667 633Q766 571 766 450Q766 365 723 287T611 152T455 57T279 6Q248 1 160 0Q148 0 131 0T108 -1Q72 -1 72 11Q72 24 90 40T133 64L144 68L152 88Q247 328 272 587Q275 613 272 613Q272 613 269 613Q225 610 195 602T149 579T129 556T119 532Q118 530 116 525T113 518Q102 502 80 490T37 475ZM665 407Q665 596 412 613Q403 614 383 614Q370 614 370 612Q370 598 363 542T323 357T242 103L228 69H265Q391 73 481 119Q536 148 575 188T633 268T658 338T665 392V407Z"></path></g></g><g data-mml-node="mo" transform="translate(1979,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mo" transform="translate(2368,0)"><path data-c="2B" d="M56 237T56 250T70 270H369V420L370 570Q380 583 389 583Q402 583 409 568V270H707Q722 262 722 250T707 230H409V-68Q401 -82 391 -82H389H387Q375 -82 369 -68V230H70Q56 237 56 250Z"></path></g><g data-mml-node="mo" transform="translate(3146,0)"><path data-c="2C" d="M78 35T78 60T94 103T137 121Q165 121 187 96T210 8Q210 -27 201 -60T180 -117T154 -158T130 -185T117 -194Q113 -194 104 -185T95 -172Q95 -168 106 -156T131 -126T157 -76T173 -3V9L172 8Q170 7 167 6T161 3T152 1T140 0Q113 0 96 17Z"></path></g><g data-mml-node="mo" transform="translate(3590.7,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mo" transform="translate(4368.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(4757.7,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g><g data-mml-node="mtd" transform="translate(5146.7,0)"><g data-mml-node="mi"></g><g data-mml-node="mo" transform="translate(277.8,0)"><path data-c="3D" d="M56 347Q56 360 70 367H707Q722 359 722 347Q722 336 708 328L390 327H72Q56 332 56 347ZM56 153Q56 168 72 173H708Q722 163 722 153Q722 140 707 133H70Q56 140 56 153Z"></path></g><g data-mml-node="mn" transform="translate(1333.6,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mo" transform="translate(1833.6,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mn" transform="translate(2222.6,0)"><path data-c="31" d="M213 578L200 573Q186 568 160 563T102 556H83V602H102Q149 604 189 617T245 641T273 663Q275 666 285 666Q294 666 302 660V361L303 61Q310 54 315 52T339 48T401 46H427V0H416Q395 3 257 3Q121 3 100 0H88V46H114Q136 46 152 46T177 47T193 50T201 52T207 57T213 61V578Z"></path></g><g data-mml-node="mo" transform="translate(2944.8,0)"><path data-c="2212" d="M84 237T84 250T98 270H679Q694 262 694 250T679 230H98Q84 237 84 250Z"></path></g><g data-mml-node="mn" transform="translate(3945,0)"><path data-c="32" d="M109 429Q82 429 66 447T50 491Q50 562 103 614T235 666Q326 666 387 610T449 465Q449 422 429 383T381 315T301 241Q265 210 201 149L142 93L218 92Q375 92 385 97Q392 99 409 186V189H449V186Q448 183 436 95T421 3V0H50V19V31Q50 38 56 46T86 81Q115 113 136 137Q145 147 170 174T204 211T233 244T261 278T284 308T305 340T320 369T333 401T340 431T343 464Q343 527 309 573T212 619Q179 619 154 602T119 569T109 550Q109 549 114 549Q132 549 151 535T170 489Q170 464 154 447T109 429Z"></path></g><g data-mml-node="mi" transform="translate(4445,0)"><path data-c="1D452" d="M39 168Q39 225 58 272T107 350T174 402T244 433T307 442H310Q355 442 388 420T421 355Q421 265 310 237Q261 224 176 223Q139 223 138 221Q138 219 132 186T125 128Q125 81 146 54T209 26T302 45T394 111Q403 121 406 121Q410 121 419 112T429 98T420 82T390 55T344 24T281 -1T205 -11Q126 -11 83 42T39 168ZM373 353Q367 405 305 405Q272 405 244 391T199 357T170 316T154 280T149 261Q149 260 169 260Q282 260 327 284T373 353Z"></path></g><g data-mml-node="mi" transform="translate(4911,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mi" transform="translate(5362,0)"><path data-c="1D45F" d="M21 287Q22 290 23 295T28 317T38 348T53 381T73 411T99 433T132 442Q161 442 183 430T214 408T225 388Q227 382 228 382T236 389Q284 441 347 441H350Q398 441 422 400Q430 381 430 363Q430 333 417 315T391 292T366 288Q346 288 334 299T322 328Q322 376 378 392Q356 405 342 405Q286 405 239 331Q229 315 224 298T190 165Q156 25 151 16Q138 -11 108 -11Q95 -11 87 -5T76 7T74 17Q74 30 114 189T154 366Q154 405 128 405Q107 405 92 377T68 316T57 280Q55 278 41 278H27Q21 284 21 287Z"></path></g><g data-mml-node="mo" transform="translate(5813,0)"><path data-c="28" d="M94 250Q94 319 104 381T127 488T164 576T202 643T244 695T277 729T302 750H315H319Q333 750 333 741Q333 738 316 720T275 667T226 581T184 443T167 250T184 58T225 -81T274 -167T316 -220T333 -241Q333 -250 318 -250H315H302L274 -226Q180 -141 137 -14T94 250Z"></path></g><g data-mml-node="mi" transform="translate(6202,0)"><path data-c="210E" d="M137 683Q138 683 209 688T282 694Q294 694 294 685Q294 674 258 534Q220 386 220 383Q220 381 227 388Q288 442 357 442Q411 442 444 415T478 336Q478 285 440 178T402 50Q403 36 407 31T422 26Q450 26 474 56T513 138Q516 149 519 151T535 153Q555 153 555 145Q555 144 551 130Q535 71 500 33Q466 -10 419 -10H414Q367 -10 346 17T325 74Q325 90 361 192T398 345Q398 404 354 404H349Q266 404 205 306L198 293L164 158Q132 28 127 16Q114 -11 83 -11Q69 -11 59 -2T48 16Q48 30 121 320L195 616Q195 629 188 632T149 637H128Q122 643 122 645T124 664Q129 683 137 683Z"></path></g><g data-mml-node="mo" transform="translate(6778,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g><g data-mml-node="mo" transform="translate(7167,0)"><path data-c="29" d="M60 749L64 750Q69 750 74 750H86L114 726Q208 641 251 514T294 250Q294 182 284 119T261 12T224 -76T186 -143T145 -194T113 -227T90 -246Q87 -249 86 -250H74Q66 -250 63 -250T58 -247T55 -238Q56 -237 66 -225Q221 -64 221 250T66 725Q56 737 55 738Q55 746 60 749Z"></path></g></g></g></g></g></g></svg></mjx-container></span> <span class="math inline">𝒜</span>-distance越大，意味着点击和未点击样本的embedding分布的差异越大。因此，我们可以通过<span class="math inline">𝒜(𝒟(+, −))</span>的变化来容易地衡量联合分布<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em>), <em>y</em>)</span>的变化。</p>
<p>在训练的过程中，作者计算了训练集和测试集上的<span class="math inline">𝒜(𝒟(+, −))</span>。对于测试集，在第二个epoch开始的时候<span class="math inline">𝒜(𝒟(+, −))</span>突然增加，证明了<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em><sub>untrained</sub>), <em>y</em>)</span>与<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em><sub>trained</sub>), <em>y</em>)</span>不同，<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em><sub>trained</sub>), <em>y</em>)</span>更容易拟合。对于测试集，所有的样本从始至终都没有参加训练，<span class="math inline">𝒜(𝒟(+, −))</span>也是稳定的。</p>
<h3 id="对训练样本的快速适应">对训练样本的快速适应</h3>
<p>第二个epoch，MLP可以快速地适应<span class="math inline">𝒟(<em>E</em><em>M</em><em>B</em>(<em>x</em><sub>trained</sub>), <em>y</em>)</span>，也就是说MLP的参数突然改变。作者监控每个训练step，embedding层和MLP层参数的变化（优化器计算的参数的更新值）。作者发现embedding层参数的变化总体平稳，而MLP层的变化在第二个epoch突然增加。</p>
<p><img src="/images/one-epoch_4.png"></p>

    <div>    
      <ul class="post-copyright">
        <li class="post-copyright-link">
          <strong>本文作者：</strong>
          <a href="/">sherry-500</a>
        </li>
        <li class="post-copyright-link">
          <strong>本文标题：</strong>
          <a href="{{ url_for(config.permalink) }}">
    
        <a class="" href="/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/">one-epoch phenomena in Deep Learning Recommendation Models</a>
    


</a>
        </li>
        <li class="post-copyright-link">
          <strong>本文链接：</strong>
          <a title="one-epoch phenomena in Deep Learning Recommendation Models">https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/</a>
        </li>
        <li class="post-copyright-license">
          <strong>版权声明： </strong>
          本文由 sherry-500 原创，采用 <a href="https://creativecommons.org/licenses/by-nc-nd/4.0/deed.zh" title="Attribution-NonCommercial-NoDerivatives 4.0 International" rel="license" target="_blank">CC BY-NC-ND 4.0</a>, 转载请保留以上声明信息！
        </li>
      </ul>
    </div>
  </div>
</article>


    <div class="blog-post-comments">
        <div id="utterances_thread">
            <noscript>加载评论需要在浏览器启用 JavaScript 脚本支持。</noscript>
        </div>
    </div>


        
          <div id="footer-post-container">
  <div id="footer-post">

    <div id="nav-footer" style="display: none">
      <ul>
        
          <li><a href="/">首页</a></li>
        
          <li><a href="/about/">关于</a></li>
        
          <li><a href="/archives/">归档</a></li>
        
          <li><a href="/tags/">标签</a></li>
        
          <li><a href="/categories/">分类</a></li>
        
          <li><a href="/search/">搜索</a></li>
        
          <li><a target="_blank" rel="noopener" href="http://github.com/probberechts">项目</a></li>
        
      </ul>
    </div>

    
    
      <div id="toc-footer" style="display: none">
        <ol class="toc"><li class="toc-item toc-level-3"><a class="toc-link" href="#model-related-factors"><span class="toc-number">1.</span> <span class="toc-text">Model-Related Factors</span></a><ol class="toc-child"><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%BB%93%E6%9E%84"><span class="toc-number">1.1.</span> <span class="toc-text">模型结构</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%A8%A1%E5%9E%8B%E7%9A%84%E5%8F%82%E6%95%B0%E9%87%8F"><span class="toc-number">1.2.</span> <span class="toc-text">模型的参数量</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0"><span class="toc-number">1.3.</span> <span class="toc-text">激活函数</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#batch-size"><span class="toc-number">1.4.</span> <span class="toc-text">Batch size</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#optimization-algorithm"><span class="toc-number">1.5.</span> <span class="toc-text">Optimization Algorithm</span></a></li><li class="toc-item toc-level-4"><a class="toc-link" href="#weight-decay-and-dropout"><span class="toc-number">1.6.</span> <span class="toc-text">weight decay and dropout</span></a></li></ol></li><li class="toc-item toc-level-3"><a class="toc-link" href="#feature-related-factors"><span class="toc-number">2.</span> <span class="toc-text">Feature-Related Factors</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E6%80%BB%E7%BB%93"><span class="toc-number">3.</span> <span class="toc-text">总结</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E8%81%94%E5%90%88%E5%88%86%E5%B8%83%E7%9A%84%E5%B7%AE%E5%BC%82"><span class="toc-number">4.</span> <span class="toc-text">联合分布的差异</span></a></li><li class="toc-item toc-level-3"><a class="toc-link" href="#%E5%AF%B9%E8%AE%AD%E7%BB%83%E6%A0%B7%E6%9C%AC%E7%9A%84%E5%BF%AB%E9%80%9F%E9%80%82%E5%BA%94"><span class="toc-number">5.</span> <span class="toc-text">对训练样本的快速适应</span></a></li></ol>
      </div>
    

    <div id="share-footer" style="display: none">
      <ul>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.facebook.com/sharer.php?u=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/"><i class="fab fa-facebook fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://twitter.com/share?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&text=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-twitter fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.linkedin.com/shareArticle?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-linkedin fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://pinterest.com/pin/create/bookmarklet/?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&is_video=false&description=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-pinterest fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" href="mailto:?subject=one-epoch phenomena in Deep Learning Recommendation Models&body=Check out this article: https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/"><i class="fa-solid fa-envelope fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://getpocket.com/save?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-get-pocket fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://reddit.com/submit?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-reddit fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.stumbleupon.com/submit?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-stumbleupon fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://digg.com/submit?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&title=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-digg fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="http://www.tumblr.com/share/link?url=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&name=one-epoch phenomena in Deep Learning Recommendation Models&description="><i class="fab fa-tumblr fa-lg" aria-hidden="true"></i></a></li>
  <li><a class="icon" target="_blank" rel="noopener" href="https://news.ycombinator.com/submitlink?u=https://sherry-500.github.io/2025/08/04/one-epoch-phenomena-in-Deep-Learning-Recommendation-Models/&t=one-epoch phenomena in Deep Learning Recommendation Models"><i class="fab fa-hacker-news fa-lg" aria-hidden="true"></i></a></li>
</ul>

    </div>

    <div id="actions-footer">
        <a id="menu" class="icon" href="#" onclick="$('#nav-footer').toggle();return false;"><i class="fa-solid fa-bars fa-lg" aria-hidden="true"></i> 菜单</a>
        
          <a id="toc" class="icon" href="#" onclick="$('#toc-footer').toggle();return false;"><i class="fa-solid fa-list fa-lg" aria-hidden="true"></i> 目录</a>
        
        <a id="share" class="icon" href="#" onclick="$('#share-footer').toggle();return false;"><i class="fa-solid fa-share-alt fa-lg" aria-hidden="true"></i> 分享</a>
        <a id="top" style="display:none" class="icon" href="#" onclick="$('html, body').animate({ scrollTop: 0 }, 'fast');"><i class="fa-solid fa-chevron-up fa-lg" aria-hidden="true"></i> 返回顶部</a>
    </div>

  </div>
</div>

        
        <footer id="footer">
  <div class="footer-left">
    Copyright &copy;
    
    
    2016-2025
    sherry-500
  </div>
  <div class="footer-right">
    <nav>
      <ul>
        <!--
       --><li><a href="/">首页</a></li><!--
     --><!--
       --><li><a href="/about/">关于</a></li><!--
     --><!--
       --><li><a href="/archives/">归档</a></li><!--
     --><!--
       --><li><a href="/tags/">标签</a></li><!--
     --><!--
       --><li><a href="/categories/">分类</a></li><!--
     --><!--
       --><li><a href="/search/">搜索</a></li><!--
     --><!--
       --><li><a target="_blank" rel="noopener" href="http://github.com/probberechts">项目</a></li><!--
     -->
      </ul>
    </nav>
  </div>
</footer>

    </div>
    <!-- styles -->



  <link rel="preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" crossorigin="anonymous" onload="this.onload=null;this.rel='stylesheet'"/>

    <!-- jquery -->

  <script src="https://cdnjs.cloudflare.com/ajax/libs/jquery/3.6.0/jquery.min.js" crossorigin="anonymous"></script>




<!-- clipboard -->

  
    <script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.7/clipboard.min.js" crossorigin="anonymous"></script>
  
  <script type="text/javascript">
  $(function() {
    // copy-btn HTML
    var btn = "<span class=\"btn-copy tooltipped tooltipped-sw\" aria-label=\"复制到粘贴板！\">";
    btn += '<i class="fa-regular fa-clone"></i>';
    btn += '</span>';
    // mount it!
    $(".highlight table").before(btn);
    var clip = new ClipboardJS('.btn-copy', {
      text: function(trigger) {
        return Array.from(trigger.nextElementSibling.querySelectorAll('.code')).reduce((str,it)=>str+it.innerText+'\n','')
      }
    });
    clip.on('success', function(e) {
      e.trigger.setAttribute('aria-label', "复制成功！");
      e.clearSelection();
    })
  })
  </script>


<script src="/js/main.js"></script>

<!-- search -->

<!-- Baidu Analytics -->

<!-- Cloudflare Analytics -->

<!-- Disqus Comments -->

<!-- utterances Comments -->

    <script type="text/javascript">
      var utterances_repo = 'sherry-500/sherry-500.github.io';
      var utterances_issue_term = 'pathname';
      var utterances_label = 'Comment';
      var utterances_theme = 'github-light';

      (function(){
          var script = document.createElement('script');

          script.src = 'https://utteranc.es/client.js';
          script.setAttribute('repo', utterances_repo);
          script.setAttribute('issue-term', 'pathname');
          script.setAttribute('label', utterances_label);
          script.setAttribute('theme', utterances_theme);
          script.setAttribute('crossorigin', 'anonymous');
          script.async = true;
          (document.getElementById('utterances_thread')).appendChild(script);
      }());
  </script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>
</body>
</html>
